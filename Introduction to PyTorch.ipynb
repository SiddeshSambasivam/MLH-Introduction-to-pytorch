{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e84d4d5",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"./assets/pytorch-logo.png\" width=100>\n",
    "</p>\n",
    "\n",
    "<h2 align=\"center\">MLH Show & Tell: Introduction to PyTorch</h2>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div align=\"center\">\n",
    "    This notebook gives a introduction to pytorch. We'll be discussing about tensors, usage of computational graphs to calculate gradients and build a simple linear model to get an understanding of the workflow in PyTorch.\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "    <h3>Topics Covered</h3>\n",
    "    <ol>\n",
    "        <li>Tensors</li>\n",
    "        <li>Computational Graphs - Autograd</li>\n",
    "        <li>Datasets & Dataloaders</li>\n",
    "        <li>Linear Regression</li>\n",
    "        <li>Simple Neural Network</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355d42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe5889",
   "metadata": {},
   "source": [
    "## 1. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ffe9e",
   "metadata": {},
   "source": [
    "### 1.1 Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd237a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([]) tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.]], dtype=torch.float64),\n",
       " tensor([[4.],\n",
       "         [5.],\n",
       "         [6.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is a tensor?\n",
    "# Difference b/w tensor and Tensor\n",
    "\n",
    "print(torch.Tensor(), torch.tensor([1,2,3]))\n",
    "\n",
    "a = torch.tensor([[1], [2], [3]], dtype=float, device='cpu')\n",
    "b = torch.tensor([[4], [5], [6]], dtype=float, device='cpu')\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eda11ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4511, 0.3047, 0.4537, 0.5734]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((1,4,2)) # np.ones((1,4,2))\n",
    "torch.zeros((1,4,2))\n",
    "\n",
    "torch.rand(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f924622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([3, 1])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(a.device, a.shape, a.dtype, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499ff50",
   "metadata": {},
   "source": [
    "### 1.2 Coversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05220737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from array to tensor\n",
    "torch.from_numpy(np.array([1,2,3,4], dtype=float))\n",
    "\n",
    "# Converting from tensor to array\n",
    "a.numpy()\n",
    "\n",
    "# move tensor to device\n",
    "a = a.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0ab60",
   "metadata": {},
   "source": [
    "### 1.3 Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60169227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication operator\n",
      "tensor([[ 4.,  5.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [12., 15., 18.]], dtype=torch.float64)\n",
      "\n",
      "Multiplication matmul\n",
      "tensor([[ 4.,  5.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [12., 15., 18.]], dtype=torch.float64)\n",
      "\n",
      "Transpose\n",
      "tensor([[1., 2., 3.]], dtype=torch.float64)\n",
      "\n",
      "Sum and Mean\n",
      "tensor([6.], dtype=torch.float64) tensor(2., dtype=torch.float64)\n",
      "\n",
      "Concat tensors\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.]], dtype=torch.float64)\n",
      "\n",
      "tensor([[1., 2., 3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Multiplication\n",
    "\n",
    "print(\"Multiplication operator\")\n",
    "print(a@b.T) # 3x1 @ 1x3 -> 3x3\n",
    "print()\n",
    "# @, matmul\n",
    "\n",
    "print(\"Multiplication matmul\")\n",
    "print(torch.matmul(a, b.T))\n",
    "print()\n",
    "\n",
    "print(\"Transpose\")\n",
    "print(a.T) # Transpose\n",
    "print()\n",
    "# a.t()\n",
    "\n",
    "# Mean, Sum\n",
    "# axis = 0 is along row and axis =1 is along column\n",
    "print(\"Sum and Mean\")\n",
    "print(a.sum(axis=0), a.mean()) \n",
    "print()\n",
    "\n",
    "print(\"Concat tensors\")\n",
    "print(torch.cat([a,b], axis=0))\n",
    "print()\n",
    "\n",
    "print(a.T) # Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bc187",
   "metadata": {},
   "source": [
    "## 2. Computational Graphs - Autograd\n",
    "\n",
    "For more detailed explanation on the usage of autograd, please refer to the [official documentation](https://pytorch.org/docs/stable/notes/autograd.html).\n",
    "\n",
    "<div align='center'>\n",
    "    <font size=\"5\">$y = (a+b) * c$</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f6bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(\n",
    "    [2],\n",
    "    dtype=float,\n",
    "    device='cpu',\n",
    "    requires_grad=True\n",
    ")\n",
    "\n",
    "b = torch.tensor(\n",
    "    [5],\n",
    "    dtype=float,\n",
    "    device='cpu',\n",
    "    requires_grad=True\n",
    ")\n",
    "\n",
    "c = torch.tensor(\n",
    "    [3], \n",
    "    dtype=float,\n",
    "    device='cpu',\n",
    "    requires_grad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42109de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (a+b)*c\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec407da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c57efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.], dtype=torch.float64),\n",
       " tensor([3.], dtype=torch.float64),\n",
       " tensor([7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad, c.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27e733",
   "metadata": {},
   "source": [
    "## 3. Datasets & Data Loaders\n",
    "\n",
    "For the sake of simplicity, we use a very small subset of a dataset. \n",
    "\n",
    "<b>Goal:</b> Predict the yield of apples and oranges given the temperature, rainfall and humidty.\n",
    "\n",
    "For any given task in PyTorch, its always a good practice to great a dataset class and use a data loader to batch inputs. \n",
    "\n",
    "1. Create a dataset class\n",
    "2. Use a data loader to batch the inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b527b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: (temp, rainfall, humidity)\n",
    "inputs = np.array([\n",
    "    [73, 67, 43],  [91, 88, 64], [87, 134, 58], \n",
    "    [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "    [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "    [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "    [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([\n",
    "        [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "        [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "        [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]\n",
    "    ],\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a37d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs), len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068500d",
   "metadata": {},
   "source": [
    "### 3.1 Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1f2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, features, targets):\n",
    "        '''\n",
    "        Initialize all the features and targets\n",
    "        '''\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self,):\n",
    "        '''\n",
    "        return length of the dataset\n",
    "        '''\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        '''\n",
    "        return sample corresponding to the index\n",
    "        '''\n",
    "        \n",
    "        features = self.features[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        return {\n",
    "            \"features\": torch.tensor(\n",
    "                features,\n",
    "                dtype=torch.float,\n",
    "            ),\n",
    "            \"target\": torch.tensor(\n",
    "                target,\n",
    "                dtype=torch.float,\n",
    "            )\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee51af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(x_train, y_train)\n",
    "test_dataset = Dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca988fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'features': tensor([91., 88., 64.]), 'target': tensor([ 81., 101.])},\n",
       " {'features': tensor([73., 67., 43.]), 'target': tensor([56., 70.])})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0], test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4c346",
   "metadata": {},
   "source": [
    "### 3.2 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d657973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "    the given dataset.\n",
      "\n",
      "    The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "    iterable-style datasets with single- or multi-process loading, customizing\n",
      "    loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "    See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "    Args:\n",
      "        dataset (Dataset): dataset from which to load the data.\n",
      "        batch_size (int, optional): how many samples per batch to load\n",
      "            (default: ``1``).\n",
      "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "            at every epoch (default: ``False``).\n",
      "        sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "            samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "            implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "        batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "            returns a batch of indices at a time. Mutually exclusive with\n",
      "            :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "            and :attr:`drop_last`.\n",
      "        num_workers (int, optional): how many subprocesses to use for data\n",
      "            loading. ``0`` means that the data will be loaded in the main process.\n",
      "            (default: ``0``)\n",
      "        collate_fn (callable, optional): merges a list of samples to form a\n",
      "            mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "            map-style dataset.\n",
      "        pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "            into CUDA pinned memory before returning them.  If your data elements\n",
      "            are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "            see the example below.\n",
      "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "            the size of dataset is not divisible by the batch size, then the last batch\n",
      "            will be smaller. (default: ``False``)\n",
      "        timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "            from workers. Should always be non-negative. (default: ``0``)\n",
      "        worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      "            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "            input, after seeding and before data loading. (default: ``None``)\n",
      "        prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
      "            in advance by each worker. ``2`` means there will be a total of\n",
      "            2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
      "        persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      "            the worker processes after a dataset has been consumed once. This allows to\n",
      "            maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "\n",
      "\n",
      "    .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "                 cannot be an unpicklable object, e.g., a lambda function. See\n",
      "                 :ref:`multiprocessing-best-practices` on more details related\n",
      "                 to multiprocessing in PyTorch.\n",
      "\n",
      "    .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "                 When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "                 it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "                 rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "                 configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "                 trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "                 loading to avoid duplicate data.\n",
      "\n",
      "                 However, if sharding results in multiple workers having incomplete last batches,\n",
      "                 this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "                 be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "                 dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "                 cases in general.\n",
      "\n",
      "                 See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "                 :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "                 `Multi-process data loading`_.\n",
      "\n",
      "    .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "                 :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(torch.utils.data.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fd5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eefbee",
   "metadata": {},
   "source": [
    "## 4. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "061583e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "lr_rate = 0.001\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2dfabd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -67.8244, -158.7126],\n",
       "        [ -89.6989, -212.7721],\n",
       "        [ -76.8156, -294.7608],\n",
       "        [ -88.7237, -113.3412],\n",
       "        [ -76.1306, -228.9728],\n",
       "        [ -67.8244, -158.7126],\n",
       "        [ -89.6989, -212.7721],\n",
       "        [ -76.8156, -294.7608],\n",
       "        [ -88.7237, -113.3412],\n",
       "        [ -76.1306, -228.9728],\n",
       "        [ -67.8244, -158.7126],\n",
       "        [ -89.6989, -212.7721],\n",
       "        [ -76.8156, -294.7608],\n",
       "        [ -88.7237, -113.3412],\n",
       "        [ -76.1306, -228.9728]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.from_numpy(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d311744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1, t2, ):\n",
    "    diff = t1 - t2\n",
    "    mse_loss = torch.sum(diff * diff) / diff.numel()\n",
    "    reg_loss = w.sum() * (0.01/(2*diff.numel()))\n",
    "    \n",
    "    loss = mse_loss + reg_loss\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd233ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 139.1218023300171\n",
      "1 133.55698013305664\n",
      "2 128.40527248382568\n",
      "3 123.63406372070312\n",
      "4 119.21163940429688\n",
      "5 115.10968017578125\n",
      "6 111.30192852020264\n",
      "7 107.76474475860596\n",
      "8 104.47573709487915\n",
      "9 101.41487169265747\n",
      "10 98.5640115737915\n",
      "11 95.90546703338623\n",
      "12 93.42444324493408\n",
      "13 91.10596132278442\n",
      "14 88.937180519104\n",
      "15 86.90607404708862\n",
      "16 85.00155067443848\n",
      "17 83.21338033676147\n",
      "18 81.53253245353699\n",
      "19 79.95018172264099\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_loss=0 \n",
    "    for sample in train_dataloader:\n",
    "        \n",
    "        x = sample['features']\n",
    "        y = sample['target']\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = mse(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * 1e-5\n",
    "            b -= b.grad * 1e-5\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "    \n",
    "    print(epoch, epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff8179f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3248,  1.0848,  0.2464],\n",
       "         [-0.2468,  0.7819,  0.8386]], requires_grad=True),\n",
       " tensor([-0.4590,  0.8789], requires_grad=True))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d55ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': tensor([[69., 96., 70.]]), 'target': tensor([[103., 119.]])} \n",
      "\n",
      "True value: [103. 119.]; Prediction: [ 98.52357  117.614075]\n"
     ]
    }
   ],
   "source": [
    "for test_inputs in test_dataloader:\n",
    "\n",
    "    x = sample['features']\n",
    "    y = sample['target']\n",
    "    \n",
    "    print(sample, '\\n')\n",
    "    print(f'True value: {y.numpy()[0]}; Prediction: {model(x).detach().numpy()[0]}')\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c309843",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101a448",
   "metadata": {},
   "source": [
    "## 5. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "242cb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20e6e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(3, 3)\n",
    "        self.act1 = torch.nn.ReLU() # Activation function\n",
    "        self.linear2 = torch.nn.Linear(3, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fd64268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0911, -0.0635,  0.3031],\n",
       "         [ 0.1999,  0.1713, -0.2428]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0305, 0.1546], requires_grad=True))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear2.weight, model.linear2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e797b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99c50a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  7911.151\n",
      "Training loss:  1954.1641\n",
      "Training loss:  288.09064\n",
      "Training loss:  136.4493\n",
      "Training loss:  111.762314\n",
      "Training loss:  100.35274\n",
      "Training loss:  91.382904\n",
      "Training loss:  83.41643\n",
      "Training loss:  76.1566\n",
      "Training loss:  69.504456\n",
      "Training loss:  63.40851\n",
      "Training loss:  57.831757\n",
      "Training loss:  52.742447\n",
      "Training loss:  48.10897\n",
      "Training loss:  43.901104\n",
      "Training loss:  40.08901\n",
      "Training loss:  36.642956\n",
      "Training loss:  33.53417\n",
      "Training loss:  30.734558\n",
      "Training loss:  28.21765\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    for sample in train_dataloader:\n",
    "        \n",
    "        x,y = sample['features'], sample['target']\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = loss_fn(output, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    print('Training loss: ', loss.detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11061a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': tensor([[69., 96., 70.]]), 'target': tensor([[103., 119.]])} \n",
      "\n",
      "True value: [103. 119.]; Prediction: [ 98.921585 116.973206]\n"
     ]
    }
   ],
   "source": [
    "for test_inputs in test_dataloader:\n",
    "\n",
    "    x = sample['features']\n",
    "    y = sample['target']\n",
    "    \n",
    "    print(sample, '\\n')\n",
    "    print(f'True value: {y.numpy()[0]}; Prediction: {model(x).detach().numpy()[0]}')\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ce134",
   "metadata": {},
   "source": [
    "## Common Problems\n",
    "\n",
    "1. Always move all the inputs to the same device (`cpu` or `gpu`)\n",
    "    ```python\n",
    "    a.to('cpu')\n",
    "    ```\n",
    "2. `TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'`\n",
    "    \n",
    "   Make sure that `requires_grad=True`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41684927",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "1. Don't do lots of courses without actually practicing anything.\n",
    "\n",
    "\n",
    "2. Try to work on a new project every month with a new task (Regression, classification, clustering, recommendation, etc ...)\n",
    "\n",
    "\n",
    "3. Particpiate in kaggle competitions. Read and understand other notebooks and methods.\n",
    "\n",
    "\n",
    "4. Read review papers\n",
    "\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
